{"instruction": "How do I implement MFA for executives without disrupting their workflow?", "input": "", "output": "{\"triage_steps\": [\"Assess current executive authentication methods\", \"Identify high-risk access scenarios requiring MFA\", \"Select user-friendly MFA technologies\"], \"containment\": [\"Create emergency break-glass accounts with offline codes\", \"Enable conditional access for high-risk scenarios only\", \"Deploy pilot MFA for IT and finance teams first\"], \"remediation\": [\"Implement Azure AD Conditional Access with risk-based policies\", \"Deploy FIDO2 hardware keys for faster authentication\", \"Configure device trust for corporate-managed devices\", \"Enable single sign-on to reduce authentication friction\"], \"how\": {\"prechecks\": [\"Verify break-glass admin accounts exist and are documented\", \"Confirm service principal accounts are excluded from MFA policies\", \"Test MFA methods with pilot group before executive rollout\"], \"plan\": [\"Phase 1: Create pilot security group with IT leadership\", \"Phase 2: Deploy FIDO2 keys and train on usage\", \"Phase 3: Enable conditional access for pilot group\", \"Phase 4: Monitor for 2 weeks and gather feedback\", \"Phase 5: Expand to executives with white-glove support\", \"Phase 6: Organization-wide rollout over 3 months\"], \"apply\": [\"terraform -chdir=azure-mfa init\", \"terraform -chdir=azure-mfa apply -var=\\\"tenant_id=${TENANT_ID}\\\" -var=\\\"pilot_group_id=${PILOT_GROUP}\\\"\", \"Deploy FIDO2 keys using deployment script\", \"Test authentication flow with pilot users\"], \"validate\": [\"Run validation PowerShell script to test sign-in flows\", \"Review Azure AD sign-in logs for MFA success rates\", \"Verify break-glass accounts work without MFA\", \"Confirm helpdesk can handle MFA reset procedures\"], \"rollback\": [\"Set Conditional Access policy to 'Report-only' mode\", \"Disable MFA requirement while preserving device trust\", \"Document any user experience issues for future improvements\"], \"risk_tradeoffs\": [\"2-3 day user training period vs $120K average BEC loss\", \"5% increase in helpdesk tickets vs 95% reduction in credential theft risk\", \"FIDO2 hardware cost ($50/user) vs potential $2.1M executive account compromise\"]}, \"artifacts\": [{\"name\": \"conditional_access.tf\", \"type\": \"terraform\", \"path\": \"azure-mfa/conditional_access.tf\", \"contents\": \"# Azure AD Conditional Access for Executive MFA\\nresource \\\"azuread_conditional_access_policy\\\" \\\"executive_mfa\\\" {\\n  display_name = \\\"Executive MFA Policy\\\"\\n  state        = \\\"enabled\\\"\\n\\n  conditions {\\n    users {\\n      included_groups = [var.executive_group_id]\\n      excluded_users  = [var.break_glass_account_1, var.break_glass_account_2]\\n    }\\n\\n    applications {\\n      included_applications = [\\\"All\\\"]\\n    }\\n\\n    locations {\\n      included_locations = [\\\"All\\\"]\\n      excluded_locations = [var.trusted_network_location]\\n    }\\n\\n    client_apps = [\\\"browser\\\", \\\"mobileAppsAndDesktopClients\\\"]\\n  }\\n\\n  grant_controls {\\n    operator          = \\\"OR\\\"\\n    built_in_controls = [\\\"mfa\\\"]\\n  }\\n\\n  session_controls {\\n    sign_in_frequency {\\n      value = 8\\n      type  = \\\"hours\\\"\\n    }\\n  }\\n}\"}, {\"name\": \"variables.tf\", \"type\": \"terraform\", \"path\": \"azure-mfa/variables.tf\", \"contents\": \"variable \\\"tenant_id\\\" {\\n  description = \\\"Azure AD tenant ID\\\"\\n  type        = string\\n}\\n\\nvariable \\\"executive_group_id\\\" {\\n  description = \\\"Object ID of executive security group\\\"\\n  type        = string\\n}\\n\\nvariable \\\"break_glass_account_1\\\" {\\n  description = \\\"Object ID of first break glass account\\\"\\n  type        = string\\n}\\n\\nvariable \\\"break_glass_account_2\\\" {\\n  description = \\\"Object ID of second break glass account\\\"\\n  type        = string\\n}\\n\\nvariable \\\"trusted_network_location\\\" {\\n  description = \\\"Named location for corporate network\\\"\\n  type        = string\\n}\"}, {\"name\": \"validate_mfa.ps1\", \"type\": \"powershell\", \"path\": \"azure-mfa/validate_mfa.ps1\", \"contents\": \"# Validate MFA Implementation\\nParam(\\n    [string]$TenantId,\\n    [string]$TestUserPrincipalName\\n)\\n\\n# Connect to Azure AD\\nConnect-AzureAD -TenantId $TenantId\\n\\n# Test sign-in logs for MFA events\\n$signInLogs = Get-AzureADAuditSignInLogs -Top 50 -Filter \\\"userPrincipalName eq '$TestUserPrincipalName'\\\"\\n\\nforeach ($log in $signInLogs) {\\n    if ($log.AuthenticationRequirement -eq \\\"multiFactorAuthentication\\\") {\\n        Write-Host \\\"âœ… MFA Required: $($log.CreatedDateTime) - Status: $($log.Status.ErrorCode)\\\" -ForegroundColor Green\\n    } else {\\n        Write-Host \\\"âš ï¸  Single Factor: $($log.CreatedDateTime) - Status: $($log.Status.ErrorCode)\\\" -ForegroundColor Yellow\\n    }\\n}\\n\\n# Check Conditional Access policy status\\n$policies = Get-AzureADMSConditionalAccessPolicy\\n$mfaPolicy = $policies | Where-Object {$_.DisplayName -like \\\"*Executive MFA*\\\"}\\n\\nif ($mfaPolicy) {\\n    Write-Host \\\"âœ… Executive MFA Policy Found: $($mfaPolicy.State)\\\" -ForegroundColor Green\\n} else {\\n    Write-Host \\\"âŒ Executive MFA Policy Not Found\\\" -ForegroundColor Red\\n}\"}, {\"name\": \"deployment_runbook.md\", \"type\": \"runbook\", \"path\": \"azure-mfa/deployment_runbook.md\", \"contents\": \"# Executive MFA Deployment Runbook\\n\\n## Pre-Deployment Checklist\\n- [ ] Break-glass accounts created and documented\\n- [ ] FIDO2 hardware keys ordered (allow 2-week delivery)\\n- [ ] Pilot group created in Azure AD\\n- [ ] Helpdesk trained on MFA reset procedures\\n- [ ] Executive assistant contacts gathered\\n\\n## Deployment Steps\\n\\n### Phase 1: Infrastructure Setup (Week 1)\\n1. Create Azure AD security groups for executives\\n2. Deploy Terraform configuration for Conditional Access\\n3. Configure trusted network locations for corporate offices\\n4. Set up monitoring and alerting for authentication failures\\n\\n### Phase 2: Pilot Testing (Week 2-3)\\n1. Add IT leadership to pilot group\\n2. Distribute FIDO2 keys and provide training\\n3. Enable MFA for pilot group using conditional access\\n4. Monitor sign-in logs and gather feedback\\n\\n### Phase 3: Executive Rollout (Week 4-6)\\n1. Schedule 1:1 sessions with each executive\\n2. Provide personalized FIDO2 key setup\\n3. Add executives to MFA group gradually\\n4. Provide white-glove support for first week\\n\\n### Phase 4: Organization Rollout (Month 2-4)\\n1. Expand to department heads and managers\\n2. Roll out to all employees by department\\n3. Monitor adoption rates and address issues\\n4. Conduct quarterly access reviews\\n\\n## Emergency Procedures\\n\\n### Break-Glass Account Access\\n1. Use emergency admin accounts: admin-breakglass-01@company.com\\n2. Accounts stored in password manager with offline backup\\n3. MFA bypass configured for these accounts only\\n4. Log all emergency access usage\\n\\n### MFA Reset Process\\n1. User calls helpdesk with identity verification\\n2. Helpdesk uses privileged access workstation\\n3. Temporary MFA bypass (24 hours maximum)\\n4. User must re-register MFA methods\\n\\n## Success Metrics\\n- MFA adoption rate >95% within 90 days\\n- Authentication failure rate <2%\\n- Helpdesk MFA tickets <10 per month\\n- Zero successful credential stuffing attacks\\n\\n## Rollback Plan\\n1. Set Conditional Access policy to 'Report-only'\\n2. Communicate rollback to affected users\\n3. Investigate and resolve technical issues\\n4. Re-enable after testing corrections\"}], \"mitre\": [\"T1078 - Valid Accounts\", \"T1110 - Brute Force\"], \"guidance\": \"Start with finance and admin users first using conditional rules: require MFA for new devices, locations, or privileged access. FIDO2 keys are actually faster than typing passwords. Show executives that BEC averages $120K per incident vs $1,200/month for executive MFA licensing.\", \"citations\": [\"Microsoft Conditional Access Guide\", \"FBI IC3 BEC Report\"], \"confidence\": 0.94}"}
{"instruction": "How would I patch Exchange servers without downtime when the business team is pushing back?", "input": "", "output": "{\"triage_steps\": [\"Calculate actual business downtime costs vs security risk exposure\", \"Assess Exchange DAG configuration and load balancing\", \"Identify compensating controls during patch window\"], \"containment\": [\"Deploy Exchange Online Protection rules to block known exploits\", \"Implement web application firewall rules for Exchange\", \"Enable enhanced logging and monitoring for exploitation attempts\"], \"remediation\": [\"Use Exchange Database Availability Group for rolling updates\", \"Implement blue-green deployment with load balancer switch\", \"Deploy patches using Windows Update for Business or WSUS\", \"Validate email flow and client connectivity after each node\"], \"how\": {\"prechecks\": [\"Verify Exchange DAG health and all databases mounted\", \"Confirm load balancer health checks are working\", \"Test backup and restore procedures\", \"Validate certificate expiration dates\"], \"plan\": [\"Step 1: Patch and restart passive DAG members first\", \"Step 2: Fail over databases to patched nodes\", \"Step 3: Patch remaining active nodes\", \"Step 4: Validate all services and perform health checks\", \"Step 5: Monitor for 24 hours with rollback capability\"], \"apply\": [\"Stop-Service MSExchangeTransport\", \"Install-WindowsUpdate -MicrosoftUpdate -AcceptAll -AutoReboot\", \"Start-Service MSExchangeTransport\", \"Test-ServiceHealth -Identity $env:COMPUTERNAME\"], \"validate\": [\"Test-OutlookConnectivity -Protocol https\", \"Test-MailFlow -TargetEmailAddressDistribution InternalOnly\", \"Get-MailboxDatabaseCopyStatus | Where-Object {$_.Status -ne 'Healthy'}\", \"Check Event Logs for Exchange errors in last 2 hours\"], \"rollback\": [\"Revert to previous DAG configuration\", \"Fail databases back to original active nodes\", \"Use System Restore point created before patching\", \"Restore from backup if critical issues persist\"], \"risk_tradeoffs\": [\"2-hour maintenance window vs $5.4M average ransomware cost\", \"Temporary reduced redundancy vs permanent system compromise\", \"Scheduled downtime vs unplanned extended outage from exploitation\"]}, \"artifacts\": [{\"name\": \"exchange_patch.ps1\", \"type\": \"powershell\", \"path\": \"exchange-patching/exchange_patch.ps1\", \"contents\": \"# Exchange Server Rolling Patch Script\\nParam(\\n    [string[]]$ExchangeServers,\\n    [string]$PatchPackage,\\n    [switch]$WhatIf\\n)\\n\\n# Verify Exchange health before starting\\nforeach ($Server in $ExchangeServers) {\\n    Write-Host \\\"Checking health of $Server...\\\"\\n    $Health = Test-ServiceHealth -Identity $Server\\n    if ($Health.ServicesNotRunning) {\\n        Write-Error \\\"âŒ $Server has unhealthy services. Aborting patch process.\\\"\\n        exit 1\\n    }\\n    Write-Host \\\"âœ… $Server is healthy\\\" -ForegroundColor Green\\n}\\n\\n# Get DAG configuration\\n$DAG = Get-DatabaseAvailabilityGroup\\n$Databases = Get-MailboxDatabase | Where-Object {$_.DatabaseAvailabilityGroup -eq $DAG.Name}\\n\\n# Patch passive nodes first\\nforeach ($Server in $ExchangeServers) {\\n    Write-Host \\\"\\n=== Patching $Server ===\\\"\\n    \\n    # Check if server has active databases\\n    $ActiveDBs = $Databases | Where-Object {$_.Server -eq $Server}\\n    \\n    if ($ActiveDBs) {\\n        Write-Host \\\"Moving active databases from $Server...\\\"\\n        foreach ($DB in $ActiveDBs) {\\n            if (-not $WhatIf) {\\n                Move-ActiveMailboxDatabase -Identity $DB.Name -ActivateOnServer ($ExchangeServers | Where-Object {$_ -ne $Server})[0] -Confirm:$false\\n            }\\n            Write-Host \\\"Moved $($DB.Name) from $Server\\\"\\n        }\\n    }\\n    \\n    # Apply patches\\n    Write-Host \\\"Installing patches on $Server...\\\"\\n    if (-not $WhatIf) {\\n        Invoke-Command -ComputerName $Server -ScriptBlock {\\n            Start-Process -FilePath $using:PatchPackage -ArgumentList '/quiet /norestart' -Wait\\n            Restart-Computer -Force\\n        }\\n    }\\n    \\n    # Wait for server to come back online\\n    Write-Host \\\"Waiting for $Server to restart...\\\"\\n    do {\\n        Start-Sleep 30\\n        $Online = Test-Connection -ComputerName $Server -Count 1 -Quiet\\n    } while (-not $Online)\\n    \\n    # Verify services are running\\n    Start-Sleep 60\\n    $PostPatchHealth = Test-ServiceHealth -Identity $Server\\n    if ($PostPatchHealth.ServicesNotRunning) {\\n        Write-Error \\\"âŒ $Server failed health check after patching\\\"\\n    } else {\\n        Write-Host \\\"âœ… $Server patched successfully\\\" -ForegroundColor Green\\n    }\\n}\\n\\nWrite-Host \\\"\\nðŸŽ‰ Exchange patching completed successfully!\\\"\"}, {\"name\": \"load_balancer_config.tf\", \"type\": \"terraform\", \"path\": \"exchange-patching/load_balancer_config.tf\", \"contents\": \"# Azure Load Balancer for Exchange High Availability\\nresource \\\"azurerm_lb\\\" \\\"exchange_lb\\\" {\\n  name                = \\\"exchange-lb\\\"\\n  location            = var.location\\n  resource_group_name = var.resource_group_name\\n  sku                 = \\\"Standard\\\"\\n\\n  frontend_ip_configuration {\\n    name                 = \\\"exchange-frontend\\\"\\n    subnet_id           = var.subnet_id\\n    private_ip_address_allocation = \\\"Static\\\"\\n    private_ip_address  = var.lb_ip_address\\n  }\\n}\\n\\n# Backend pool for Exchange servers\\nresource \\\"azurerm_lb_backend_address_pool\\\" \\\"exchange_pool\\\" {\\n  name            = \\\"exchange-backend-pool\\\"\\n  loadbalancer_id = azurerm_lb.exchange_lb.id\\n}\\n\\n# Health probe for Exchange services\\nresource \\\"azurerm_lb_probe\\\" \\\"exchange_probe\\\" {\\n  name                = \\\"exchange-health-probe\\\"\\n  loadbalancer_id     = azurerm_lb.exchange_lb.id\\n  protocol            = \\\"Https\\\"\\n  port                = 443\\n  request_path        = \\\"/owa/healthcheck.htm\\\"\\n  interval_in_seconds = 30\\n  number_of_probes    = 3\\n}\\n\\n# Load balancing rule for HTTPS\\nresource \\\"azurerm_lb_rule\\\" \\\"exchange_https\\\" {\\n  name                           = \\\"exchange-https-rule\\\"\\n  loadbalancer_id               = azurerm_lb.exchange_lb.id\\n  protocol                      = \\\"Tcp\\\"\\n  frontend_port                 = 443\\n  backend_port                  = 443\\n  frontend_ip_configuration_name = \\\"exchange-frontend\\\"\\n  backend_address_pool_ids      = [azurerm_lb_backend_address_pool.exchange_pool.id]\\n  probe_id                      = azurerm_lb_probe.exchange_probe.id\\n  enable_floating_ip           = true\\n}\"}, {\"name\": \"patch_validation.ps1\", \"type\": \"powershell\", \"path\": \"exchange-patching/patch_validation.ps1\", \"contents\": \"# Exchange Patch Validation Script\\nParam(\\n    [string[]]$ExchangeServers = @(),\\n    [string]$TestMailbox = 'testuser@company.com'\\n)\\n\\nWrite-Host \\\"=== Exchange Patch Validation ==\\\" -ForegroundColor Cyan\\n\\n# Test 1: Service Health\\nforeach ($Server in $ExchangeServers) {\\n    Write-Host \\\"\\nTesting service health on $Server...\\\"\\n    try {\\n        $Health = Test-ServiceHealth -Identity $Server\\n        if ($Health.ServicesNotRunning.Count -eq 0) {\\n            Write-Host \\\"âœ… All services running on $Server\\\" -ForegroundColor Green\\n        } else {\\n            Write-Host \\\"âŒ Services not running on $Server: $($Health.ServicesNotRunning -join ', ')\\\" -ForegroundColor Red\\n        }\\n    } catch {\\n        Write-Host \\\"âŒ Failed to check service health on $Server: $($_.Exception.Message)\\\" -ForegroundColor Red\\n    }\\n}\\n\\n# Test 2: Database Availability\\nWrite-Host \\\"\\nTesting database availability...\\\"\\ntry {\\n    $DBStatus = Get-MailboxDatabaseCopyStatus | Where-Object {$_.Status -ne 'Healthy'}\\n    if ($DBStatus.Count -eq 0) {\\n        Write-Host \\\"âœ… All database copies are healthy\\\" -ForegroundColor Green\\n    } else {\\n        Write-Host \\\"âŒ Unhealthy database copies found:\\\" -ForegroundColor Red\\n        $DBStatus | Format-Table Name, Server, Status -AutoSize\\n    }\\n} catch {\\n    Write-Host \\\"âŒ Failed to check database status: $($_.Exception.Message)\\\" -ForegroundColor Red\\n}\\n\\n# Test 3: Mail Flow\\nWrite-Host \\\"\\nTesting mail flow...\\\"\\ntry {\\n    $MailFlowTest = Test-MailFlow -TargetEmailAddress $TestMailbox -TargetDatabase (Get-MailboxDatabase)[0].Name\\n    if ($MailFlowTest.TestMailflowResult -eq 'Success') {\\n        Write-Host \\\"âœ… Mail flow test successful\\\" -ForegroundColor Green\\n    } else {\\n        Write-Host \\\"âŒ Mail flow test failed: $($MailFlowTest.Error)\\\" -ForegroundColor Red\\n    }\\n} catch {\\n    Write-Host \\\"âŒ Failed to test mail flow: $($_.Exception.Message)\\\" -ForegroundColor Red\\n}\\n\\n# Test 4: Client Connectivity\\nWrite-Host \\\"\\nTesting client connectivity...\\\"\\ntry {\\n    $ConnectivityTests = @('OutlookAnywhere', 'EWS', 'OWA')\\n    foreach ($Test in $ConnectivityTests) {\\n        $Result = Test-OutlookConnectivity -ClientAccessServer $ExchangeServers[0] -Protocol $Test\\n        if ($Result.Result -eq 'Success') {\\n            Write-Host \\\"âœ… $Test connectivity successful\\\" -ForegroundColor Green\\n        } else {\\n            Write-Host \\\"âŒ $Test connectivity failed\\\" -ForegroundColor Red\\n        }\\n    }\\n} catch {\\n    Write-Host \\\"âŒ Failed to test client connectivity: $($_.Exception.Message)\\\" -ForegroundColor Red\\n}\\n\\n# Test 5: Certificate Validation\\nWrite-Host \\\"\\nValidating certificates...\\\"\\nforeach ($Server in $ExchangeServers) {\\n    try {\\n        $Certs = Get-ExchangeCertificate -Server $Server | Where-Object {$_.Services -match 'IIS'}\\n        foreach ($Cert in $Certs) {\\n            if ($Cert.NotAfter -lt (Get-Date).AddDays(30)) {\\n                Write-Host \\\"âš ï¸  Certificate expiring soon on $Server: $($Cert.Subject)\\\" -ForegroundColor Yellow\\n            } else {\\n                Write-Host \\\"âœ… Certificate valid on $Server\\\" -ForegroundColor Green\\n            }\\n        }\\n    } catch {\\n        Write-Host \\\"âŒ Failed to check certificates on $Server: $($_.Exception.Message)\\\" -ForegroundColor Red\\n    }\\n}\\n\\nWrite-Host \\\"\\n=== Validation Complete ===\\\" -ForegroundColor Cyan\"}, {\"name\": \"business_justification.md\", \"type\": \"runbook\", \"path\": \"exchange-patching/business_justification.md\", \"contents\": \"# Exchange Patching Business Justification\\n\\n## Executive Summary\\n\\n**Problem**: Critical Exchange security patches require system restart, business teams resist 2-hour maintenance window citing revenue impact.\\n\\n**Solution**: Rolling patch deployment using Database Availability Groups (DAG) for zero-downtime patching.\\n\\n**Business Impact**: 2-hour planned maintenance costs $50,000 in lost productivity vs $5.4M average cost of Exchange ransomware incident.\\n\\n## Risk Analysis\\n\\n### Current Risk Exposure\\n- **Vulnerability**: CVE-2024-XXXX Exchange ProxyShell variant (CVSS 9.8)\\n- **Exploit Probability**: 87% based on threat intelligence (active exploitation detected)\\n- **Business Impact**: Email system compromise = complete business disruption\\n- **Financial Impact**: $5.4M average ransomware recovery + $2.1M regulatory fines + reputation damage\\n\\n### Patching Costs\\n- **Maintenance Window**: 2 hours during off-peak (Saturday 2-4 AM)\\n- **Staff Costs**: $5,000 (overtime for 4 engineers)\\n- **Business Impact**: Minimal (Saturday early morning, international sales unaffected)\\n- **Total Cost**: $5,000\\n\\n### ROI Calculation\\n- **Risk Mitigation**: $5.4M potential loss avoided\\n- **Implementation Cost**: $5,000\\n- **ROI**: 1,080:1 return on investment\\n\\n## Technical Approach\\n\\n### Zero-Downtime Strategy\\n1. **Database Availability Groups**: Use Exchange DAG for automatic failover\\n2. **Rolling Updates**: Patch passive nodes first, then fail over active databases\\n3. **Load Balancer**: Configure health checks to route traffic away from patching nodes\\n4. **Monitoring**: Real-time monitoring of email flow during patching process\\n\\n### Rollback Plan\\n1. **Immediate Rollback**: Fail databases back to original active nodes (5 minutes)\\n2. **System Restore**: Use automatic restore points created before patching\\n3. **Backup Recovery**: Full system recovery from nightly backups (2 hours maximum)\\n\\n## Stakeholder Communication\\n\\n### For Executive Team\\n\\\"We can patch Exchange with zero email downtime using our high-availability configuration. This eliminates the $5.4M ransomware risk for a $5,000 engineering investment - delivering 1,080x ROI while maintaining business continuity.\\\"\\n\\n### For Business Teams\\n\\\"Email services will remain available throughout the patching process. Users may experience a brief reconnection (30 seconds) as Outlook switches to healthy servers automatically. No action required from users.\\\"\\n\\n### For Technical Teams\\n\\\"Rolling patch deployment leverages DAG automatic failover with load balancer health checks. Each node patched individually with validation before proceeding to next server.\\\"\\n\\n## Success Metrics\\n- **Email Availability**: >99.9% during patching window\\n- **User Impact**: <1% users report connectivity issues\\n- **Patch Success Rate**: 100% successful patch deployment\\n- **Rollback Time**: <5 minutes if issues detected\\n\\n## Compliance Benefits\\n- **SOX Compliance**: Demonstrates due diligence in protecting financial systems\\n- **Cyber Insurance**: Maintains coverage by following vendor security guidance\\n- **Regulatory**: Meets SEC cybersecurity disclosure requirements\\n- **Industry Standards**: Aligns with NIST Cybersecurity Framework requirements\"}], \"mitre\": [\"T1190 - Exploit Public-Facing Application\"], \"guidance\": \"Present the business case: 2-hour planned outage costs $50K vs $5.4M average ransomware. Use Exchange DAG for rolling updates - patch passive nodes first, fail over databases, then patch remaining nodes. Zero-downtime is achievable with proper architecture.\", \"citations\": [\"Microsoft Exchange Best Practices\", \"IBM Cost of Breach 2024\"], \"confidence\": 0.91}"}
{"instruction": "How do I implement Zero Trust architecture when the network team says it will break legacy applications?", "input": "", "output": "{\"triage_steps\": [\"Inventory all legacy applications and their network dependencies\", \"Assess current network trust assumptions and implicit access\", \"Map application communication flows and authentication methods\"], \"containment\": [\"Implement network micro-segmentation for new applications first\", \"Deploy software-defined perimeter for remote access users\", \"Enable enhanced logging for all network traffic\"], \"remediation\": [\"Phase Zero Trust adoption starting with cloud-native applications\", \"Deploy identity-based network access controls\", \"Implement application-layer authentication and authorization\", \"Use network access control (NAC) for legacy system accommodation\"], \"how\": {\"prechecks\": [\"Complete network traffic analysis for application dependencies\", \"Document all service accounts and their access requirements\", \"Verify network monitoring and logging capabilities\", \"Test application behavior with increased network latency\"], \"plan\": [\"Phase 1: Implement identity verification for all users and devices\", \"Phase 2: Deploy micro-segmentation for new applications\", \"Phase 3: Create application proxy layer for legacy systems\", \"Phase 4: Implement least privilege access policies\", \"Phase 5: Enable continuous verification and monitoring\"], \"apply\": [\"Deploy Palo Alto Prisma SASE solution\", \"Configure Okta Universal Directory with device trust\", \"Implement Zscaler Private Access for application access\", \"Deploy CrowdStrike Falcon for endpoint verification\"], \"validate\": [\"Test application connectivity through zero trust architecture\", \"Verify user experience remains acceptable (<2 second auth delay)\", \"Confirm legacy applications function with network access control\", \"Validate security logging and monitoring effectiveness\"], \"rollback\": [\"Revert to original network ACLs and firewall rules\", \"Disable zero trust policies while maintaining device visibility\", \"Document application compatibility issues for remediation\"], \"risk_tradeoffs\": [\"6-month implementation timeline vs immediate lateral movement protection\", \"Legacy application compatibility effort vs $1.76M lateral movement damage\", \"User experience adjustment vs 90% reduction in network attack surface\"]}, \"artifacts\": [{\"name\": \"zero_trust_architecture.tf\", \"type\": \"terraform\", \"path\": \"zero-trust/zero_trust_architecture.tf\", \"contents\": \"# Zero Trust Network Architecture\\n\\n# Palo Alto Prisma Access configuration\\nresource \\\"prismaaccess_service_connection\\\" \\\"corporate\\\" {\\n  name        = \\\"corporate-ztna\\\"\\n  region      = var.region\\n  subnets     = var.corporate_subnets\\n  \\n  # Application access policies\\n  applications {\\n    name = \\\"internal-web-apps\\\"\\n    domains = [\\\"*.internal.company.com\\\"]\\n    ports = [\\\"80\\\", \\\"443\\\"]\\n  }\\n}\\n\\n# Identity-based access control\\nresource \\\"okta_policy_rule_signon\\\" \\\"zero_trust_access\\\" {\\n  policy_id = okta_policy_signon.zero_trust.id\\n  name      = \\\"Zero Trust Access Rule\\\"\\n  priority  = 1\\n  status    = \\\"ACTIVE\\\"\\n\\n  conditions {\\n    people {\\n      groups {\\n        include = [okta_group.employees.id]\\n      }\\n    }\\n    \\n    network {\\n      connection = \\\"ANYWHERE\\\"\\n    }\\n    \\n    device {\\n      managed   = true\\n      registered = true\\n    }\\n  }\\n\\n  actions {\\n    signon {\\n      access = \\\"ALLOW\\\"\\n      require_factor = \\\"true\\\"\\n      factor_prompt_mode = \\\"SESSION\\\"\\n      session {\\n        max_session_idle_minutes = 120\\n        max_session_lifetime_minutes = 480\\n      }\\n    }\\n  }\\n}\\n\\n# Network micro-segmentation\\nresource \\\"panos_security_policy\\\" \\\"micro_segmentation\\\" {\\n  rule {\\n    name                  = \\\"allow-web-to-db\\\"\\n    source_zones          = [\\\"web-tier\\\"]\\n    source_addresses      = [\\\"any\\\"]\\n    destination_zones     = [\\\"db-tier\\\"]\\n    destination_addresses = [var.database_servers]\\n    applications          = [\\\"mysql\\\", \\\"mssql\\\"]\\n    services             = [\\\"application-default\\\"]\\n    categories           = [\\\"any\\\"]\\n    action               = \\\"allow\\\"\\n    log_setting          = \\\"default\\\"\\n  }\\n\\n  rule {\\n    name                  = \\\"deny-lateral-movement\\\"\\n    source_zones          = [\\\"any\\\"]\\n    source_addresses      = [\\\"any\\\"]\\n    destination_zones     = [\\\"any\\\"]\\n    destination_addresses = [\\\"any\\\"]\\n    applications          = [\\\"any\\\"]\\n    services             = [\\\"any\\\"]\\n    categories           = [\\\"any\\\"]\\n    action               = \\\"deny\\\"\\n    log_setting          = \\\"default\\\"\\n  }\\n}\"}, {\"name\": \"legacy_application_proxy.yaml\", \"type\": \"kubernetes\", \"path\": \"zero-trust/legacy_application_proxy.yaml\", \"contents\": \"# Application Proxy for Legacy Systems\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: legacy-app-proxy\\n  namespace: zero-trust\\nspec:\\n  replicas: 3\\n  selector:\\n    matchLabels:\\n      app: legacy-app-proxy\\n  template:\\n    metadata:\\n      labels:\\n        app: legacy-app-proxy\\n    spec:\\n      containers:\\n      - name: envoy-proxy\\n        image: envoyproxy/envoy:v1.28-latest\\n        ports:\\n        - containerPort: 8080\\n        - containerPort: 8443\\n        volumeMounts:\\n        - name: envoy-config\\n          mountPath: /etc/envoy\\n        env:\\n        - name: LEGACY_APP_HOST\\n          value: \\\"legacy-erp.internal.company.com\\\"\\n        - name: LEGACY_APP_PORT\\n          value: \\\"8080\\\"\\n      volumes:\\n      - name: envoy-config\\n        configMap:\\n          name: envoy-config\\n---\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: envoy-config\\n  namespace: zero-trust\\ndata:\\n  envoy.yaml: |\\n    static_resources:\\n      listeners:\\n      - name: legacy_app_listener\\n        address:\\n          socket_address:\\n            address: 0.0.0.0\\n            port_value: 8080\\n        filter_chains:\\n        - filters:\\n          - name: envoy.filters.network.http_connection_manager\\n            typed_config:\\n              '@type': type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\\n              codec_type: AUTO\\n              stat_prefix: legacy_app\\n              route_config:\\n                name: local_route\\n                virtual_hosts:\\n                - name: legacy_app\\n                  domains: ['*']\\n                  routes:\\n                  - match: { prefix: '/' }\\n                    route: { cluster: legacy_app_cluster }\\n              http_filters:\\n              - name: envoy.filters.http.ext_authz\\n                typed_config:\\n                  '@type': type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthz\\n                  http_service:\\n                    server_uri:\\n                      uri: http://oauth2-proxy.zero-trust.svc.cluster.local\\n                      cluster: oauth2_proxy\\n                      timeout: 5s\\n              - name: envoy.filters.http.router\\n      clusters:\\n      - name: legacy_app_cluster\\n        connect_timeout: 5s\\n        type: LOGICAL_DNS\\n        dns_lookup_family: V4_ONLY\\n        load_assignment:\\n          cluster_name: legacy_app_cluster\\n          endpoints:\\n          - lb_endpoints:\\n            - endpoint:\\n                address:\\n                  socket_address:\\n                    address: ${LEGACY_APP_HOST}\\n                    port_value: ${LEGACY_APP_PORT}\\n      - name: oauth2_proxy\\n        connect_timeout: 5s\\n        type: LOGICAL_DNS\\n        dns_lookup_family: V4_ONLY\\n        load_assignment:\\n          cluster_name: oauth2_proxy\\n          endpoints:\\n          - lb_endpoints:\\n            - endpoint:\\n                address:\\n                  socket_address:\\n                    address: oauth2-proxy.zero-trust.svc.cluster.local\\n                    port_value: 4180\"}, {\"name\": \"device_compliance_policy.json\", \"type\": \"json\", \"path\": \"zero-trust/device_compliance_policy.json\", \"contents\": \"{\\n  \\\"@odata.type\\\": \\\"#microsoft.graph.windows10CompliancePolicy\\\",\\n  \\\"displayName\\\": \\\"Windows 10 Zero Trust Compliance\\\",\\n  \\\"description\\\": \\\"Device compliance requirements for Zero Trust access\\\",\\n  \\\"passwordRequired\\\": true,\\n  \\\"passwordMinimumLength\\\": 12,\\n  \\\"passwordRequiredType\\\": \\\"alphanumeric\\\",\\n  \\\"passwordMinutesOfInactivityBeforeLock\\\": 15,\\n  \\\"passwordExpirationDays\\\": 90,\\n  \\\"passwordPreviousPasswordBlockCount\\\": 12,\\n  \\\"requireHealthyDeviceReport\\\": true,\\n  \\\"osMinimumVersion\\\": \\\"10.0.19041\\\",\\n  \\\"osMaximumVersion\\\": null,\\n  \\\"mobileOsMinimumVersion\\\": null,\\n  \\\"mobileOsMaximumVersion\\\": null,\\n  \\\"earlyLaunchAntiMalwareDriverEnabled\\\": true,\\n  \\\"bitLockerEnabled\\\": true,\\n  \\\"secureBootEnabled\\\": true,\\n  \\\"codeIntegrityEnabled\\\": true,\\n  \\\"storageRequireEncryption\\\": true,\\n  \\\"activeFirewallRequired\\\": true,\\n  \\\"defenderEnabled\\\": true,\\n  \\\"defenderVersion\\\": null,\\n  \\\"signatureOutOfDate\\\": false,\\n  \\\"rtpEnabled\\\": true,\\n  \\\"antivirusRequired\\\": true,\\n  \\\"antiSpywareRequired\\\": true,\\n  \\\"deviceThreatProtectionEnabled\\\": true,\\n  \\\"deviceThreatProtectionRequiredSecurityLevel\\\": \\\"medium\\\",\\n  \\\"configurationManagerComplianceRequired\\\": false,\\n  \\\"tpmRequired\\\": true,\\n  \\\"deviceCompliancePolicyScript\\\": null,\\n  \\\"validOperatingSystemBuildRanges\\\": []\\n}\"}, {\"name\": \"implementation_roadmap.md\", \"type\": \"runbook\", \"path\": \"zero-trust/implementation_roadmap.md\", \"contents\": \"# Zero Trust Implementation Roadmap\\n\\n## Phase 1: Foundation (Months 1-2)\\n\\n### Identity and Device Verification\\n- [ ] Deploy unified endpoint management (Microsoft Intune/VMware Workspace ONE)\\n- [ ] Implement device compliance policies with BitLocker, antivirus, and patching requirements\\n- [ ] Configure conditional access policies based on user + device + location signals\\n- [ ] Deploy privileged access workstations (PAWs) for administrative tasks\\n\\n### Immediate Security Wins\\n- [ ] Enable MFA for all users with risk-based policies\\n- [ ] Deploy endpoint detection and response (EDR) on all devices\\n- [ ] Implement just-in-time privileged access management\\n- [ ] Enable security defaults in Azure AD/Office 365\\n\\n## Phase 2: Network Segmentation (Months 3-4)\\n\\n### Micro-segmentation\\n- [ ] Map application dependencies and communication flows\\n- [ ] Implement software-defined networking (SDN) with identity-based policies\\n- [ ] Deploy network access control (NAC) for device authentication\\n- [ ] Configure firewall rules based on application requirements, not IP addresses\\n\\n### Legacy Application Accommodation\\n- [ ] Deploy application delivery controllers (ADCs) with authentication proxy\\n- [ ] Implement VPN replacement with zero trust network access (ZTNA)\\n- [ ] Configure legacy application wrapper with modern authentication\\n- [ ] Create application-specific access policies\\n\\n## Phase 3: Data Protection (Months 5-6)\\n\\n### Data Classification and Protection\\n- [ ] Implement data classification and labeling (Microsoft Purview/Varonis)\\n- [ ] Deploy data loss prevention (DLP) with policy enforcement\\n- [ ] Configure rights management for sensitive documents\\n- [ ] Enable cloud app security (CASB) for SaaS applications\\n\\n### Encryption and Key Management\\n- [ ] Deploy always-on encryption for data at rest and in transit\\n- [ ] Implement certificate-based authentication where possible\\n- [ ] Configure key management service with hardware security modules\\n- [ ] Enable database encryption and tokenization for PCI/PHI data\\n\\n## Phase 4: Continuous Verification (Months 7-8)\\n\\n### Monitoring and Analytics\\n- [ ] Deploy user and entity behavior analytics (UEBA)\\n- [ ] Implement security information and event management (SIEM) with zero trust use cases\\n- [ ] Configure automated threat response and orchestration (SOAR)\\n- [ ] Enable cloud security posture management (CSPM)\\n\\n### Risk-Based Access\\n- [ ] Implement adaptive authentication based on risk scores\\n- [ ] Deploy step-up authentication for sensitive operations\\n- [ ] Configure session controls based on real-time risk assessment\\n- [ ] Enable automated access reviews and certification\\n\\n## Legacy Application Strategy\\n\\n### Application Modernization\\n1. **Assess and Prioritize**: Categorize applications by business criticality and modernization feasibility\\n2. **Authentication Wrapper**: Deploy reverse proxy with modern authentication for immediate protection\\n3. **API Gateway**: Expose legacy functionality through modern API layer with proper authorization\\n4. **Gradual Migration**: Plan application refactoring or replacement over 2-3 year timeline\\n\\n### Network Accommodation\\n1. **VLAN Segmentation**: Use traditional VLANs as interim solution for legacy systems\\n2. **Application Firewall**: Deploy application-layer firewalls for legacy protocol support\\n3. **Proxy Services**: Route legacy traffic through authenticated proxy services\\n4. **Monitoring**: Enhanced logging and monitoring for legacy application access\\n\\n## Success Metrics\\n\\n### Security Metrics\\n- 99.9% device compliance rate within 90 days\\n- 95% reduction in lateral movement attempts\\n- <5% false positive rate for access decisions\\n- Zero successful credential stuffing attacks\\n\\n### User Experience Metrics\\n- <2 second average authentication time\\n- <5% increase in helpdesk tickets during rollout\\n- >90% user satisfaction with new access methods\\n- <1% business application downtime during implementation\\n\\n### Business Metrics\\n- 40% reduction in security incidents within 6 months\\n- 60% faster incident response and containment\\n- 100% compliance with cyber insurance requirements\\n- ROI positive within 18 months through reduced breach risk\\n\\n## Risk Mitigation\\n\\n### Technical Risks\\n- **Legacy App Breakage**: Maintain network bypass capability for critical applications\\n- **Performance Impact**: Deploy caching and optimization for authentication flows\\n- **Certificate Issues**: Implement robust PKI with automated certificate lifecycle management\\n- **Network Latency**: Use regional access points and CDN for global users\\n\\n### Business Risks\\n- **User Productivity**: Provide extensive training and white-glove support during rollout\\n- **Vendor Dependencies**: Maintain hybrid/multi-vendor approach to avoid lock-in\\n- **Compliance Gaps**: Engage compliance team early to validate requirements\\n- **Budget Overruns**: Phase implementation to spread costs and demonstrate ROI\"}], \"mitre\": [\"T1021 - Remote Services\", \"T1078 - Valid Accounts\"], \"guidance\": \"NIST SP 800-207 defines Zero Trust as 'never trust, always verify'. Start with identity and device verification, then add network micro-segmentation. Legacy applications can be accommodated through application proxies and network access control. The key is gradual implementation with legacy compatibility.\", \"citations\": [\"NIST SP 800-207\", \"Microsoft Zero Trust Guide\"], \"confidence\": 0.88}"}
{"instruction": "How do I implement secure SDLC when developers are complaining about security slowing them down?", "input": "", "output": "{\"triage_steps\": [\"Assess current development workflow and security touchpoints\", \"Measure actual time impact of security activities\", \"Identify high-friction security processes for optimization\"], \"containment\": [\"Implement basic security scanning in parallel with builds\", \"Deploy pre-commit hooks for immediate security feedback\", \"Enable dependency vulnerability scanning with risk-based blocking\"], \"remediation\": [\"Integrate security tools into CI/CD pipeline for shift-left approach\", \"Implement security as code with Infrastructure as Code templates\", \"Deploy developer security training with hands-on exercises\", \"Create security champion program within development teams\"], \"how\": {\"prechecks\": [\"Baseline current build times and deployment frequency\", \"Survey developer satisfaction with current security processes\", \"Inventory all security tools and their integration points\", \"Document current code review and approval processes\"], \"plan\": [\"Phase 1: Optimize existing security tools to run in parallel\", \"Phase 2: Implement shift-left security with IDE integration\", \"Phase 3: Deploy security as code and policy automation\", \"Phase 4: Establish continuous security monitoring and feedback\", \"Phase 5: Create security metrics and developer incentives\"], \"apply\": [\"Deploy Snyk for IDE-integrated vulnerability scanning\", \"Configure SonarQube for automated code quality and security analysis\", \"Implement GitLab Security Dashboards with merge request integration\", \"Deploy Falco for runtime security monitoring in Kubernetes\"], \"validate\": [\"Measure build time impact (<5% increase acceptable)\", \"Track developer velocity metrics (story points, deployment frequency)\", \"Monitor security findings remediation time and false positive rates\", \"Survey developer satisfaction with new security workflow\"], \"rollback\": [\"Disable security gates temporarily while maintaining scanning\", \"Revert to manual security reviews for critical findings only\", \"Document process improvements and developer feedback\"], \"risk_tradeoffs\": [\"2-minute build time increase vs $2.8M average application security breach\", \"Developer workflow adjustment vs 75% reduction in production vulnerabilities\", \"Security tool licensing costs vs avoiding $4.45M average data breach\"]}, \"artifacts\": [{\"name\": \"gitlab_security_pipeline.yml\", \"type\": \"yaml\", \"path\": \"secure-sdlc/gitlab_security_pipeline.yml\", \"contents\": \"# GitLab CI/CD Security Pipeline\\nstages:\\n  - build\\n  - test\\n  - security\\n  - deploy\\n\\nvariables:\\n  SECURE_ANALYZERS_PREFIX: \\\"$CI_TEMPLATE_REGISTRY_HOST/security-products\\\"\\n\\n# Build stage\\nbuild_application:\\n  stage: build\\n  script:\\n    - echo \\\"Building application...\\\"\\n    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .\\n    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\\n  only:\\n    - merge_requests\\n    - main\\n\\n# Security scanning in parallel\\nsast_scan:\\n  stage: security\\n  include:\\n    - template: Security/SAST.gitlab-ci.yml\\n  variables:\\n    SAST_EXCLUDED_PATHS: \\\"spec, test, tests, tmp\\\"\\n  allow_failure: false\\n  only:\\n    - merge_requests\\n    - main\\n\\ndependency_scanning:\\n  stage: security\\n  include:\\n    - template: Security/Dependency-Scanning.gitlab-ci.yml\\n  variables:\\n    DS_EXCLUDE_PATHS: \\\"spec, test, tests, tmp\\\"\\n  allow_failure: false\\n  only:\\n    - merge_requests\\n    - main\\n\\ncontainer_scanning:\\n  stage: security\\n  include:\\n    - template: Security/Container-Scanning.gitlab-ci.yml\\n  variables:\\n    CS_IMAGE: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\\n    CS_SEVERITY_THRESHOLD: \\\"HIGH\\\"\\n  allow_failure: false\\n  dependencies:\\n    - build_application\\n  only:\\n    - merge_requests\\n    - main\\n\\nsecret_detection:\\n  stage: security\\n  include:\\n    - template: Security/Secret-Detection.gitlab-ci.yml\\n  allow_failure: false\\n  only:\\n    - merge_requests\\n    - main\\n\\n# Security policy as code\\nsecurity_policy_check:\\n  stage: security\\n  image: openpolicyagent/opa:latest\\n  script:\\n    - opa fmt --diff policies/\\n    - opa test policies/\\n    - opa eval -d policies/ -i security_scan_results.json \\\"data.security.allow\\\"\\n  artifacts:\\n    reports:\\n      junit: policy_test_results.xml\\n  only:\\n    - merge_requests\\n    - main\\n\\n# Deployment with security validation\\ndeploy_staging:\\n  stage: deploy\\n  script:\\n    - kubectl apply -f k8s/staging/\\n    - kubectl rollout status deployment/app -n staging\\n    - sleep 30\\n    - curl -f http://staging.company.com/health || exit 1\\n  environment:\\n    name: staging\\n    url: http://staging.company.com\\n  only:\\n    - main\\n  when: manual\\n\\ndeploy_production:\\n  stage: deploy\\n  script:\\n    - kubectl apply -f k8s/production/\\n    - kubectl rollout status deployment/app -n production\\n    - sleep 60\\n    - curl -f https://app.company.com/health || exit 1\\n  environment:\\n    name: production\\n    url: https://app.company.com\\n  only:\\n    - main\\n  when: manual\\n  dependencies:\\n    - sast_scan\\n    - dependency_scanning\\n    - container_scanning\\n    - secret_detection\"}, {\"name\": \"pre_commit_hooks.yaml\", \"type\": \"yaml\", \"path\": \"secure-sdlc/pre_commit_hooks.yaml\", \"contents\": \"# Pre-commit Security Hooks Configuration\\nrepos:\\n  - repo: https://github.com/pre-commit/pre-commit-hooks\\n    rev: v4.4.0\\n    hooks:\\n      - id: trailing-whitespace\\n      - id: end-of-file-fixer\\n      - id: check-yaml\\n      - id: check-json\\n      - id: check-added-large-files\\n        args: ['--maxkb=500']\\n      - id: check-merge-conflict\\n      - id: detect-private-key\\n\\n  # Security-specific hooks\\n  - repo: https://github.com/Yelp/detect-secrets\\n    rev: v1.4.0\\n    hooks:\\n      - id: detect-secrets\\n        args: ['--baseline', '.secrets.baseline']\\n\\n  - repo: https://github.com/PyCQA/bandit\\n    rev: 1.7.5\\n    hooks:\\n      - id: bandit\\n        args: ['-r', '.', '-f', 'json', '-o', 'bandit-report.json']\\n        language_version: python3\\n\\n  - repo: https://github.com/PyCQA/safety\\n    rev: 2.3.1\\n    hooks:\\n      - id: safety\\n        language_version: python3\\n\\n  # Infrastructure as Code security\\n  - repo: https://github.com/bridgecrewio/checkov\\n    rev: 2.4.9\\n    hooks:\\n      - id: checkov\\n        args: [--framework, terraform, --framework, kubernetes, --framework, dockerfile]\\n\\n  - repo: https://github.com/aquasecurity/tfsec\\n    rev: v1.28.1\\n    hooks:\\n      - id: tfsec\\n        args: [--format, json, --out, tfsec-results.json]\\n\\n  # Container security\\n  - repo: https://github.com/hadolint/hadolint\\n    rev: v2.12.0\\n    hooks:\\n      - id: hadolint-docker\\n        args: [--format, json, --output, hadolint-report.json]\\n\\n  # Code quality and security\\n  - repo: https://github.com/psf/black\\n    rev: 23.3.0\\n    hooks:\\n      - id: black\\n        language_version: python3\\n\\n  - repo: https://github.com/PyCQA/flake8\\n    rev: 6.0.0\\n    hooks:\\n      - id: flake8\\n        additional_dependencies: [flake8-bugbear, flake8-security]\\n\\n  # License compliance\\n  - repo: https://github.com/Lucas-C/pre-commit-hooks\\n    rev: v1.5.1\\n    hooks:\\n      - id: insert-license\\n        files: \\\\.(py|js|ts|java)$\\n        args:\\n          - --license-filepath\\n          - LICENSE.txt\\n          - --comment-style\\n          - \\\"#\\\"\"}, {\"name\": \"sonarqube_config.properties\", \"type\": \"properties\", \"path\": \"secure-sdlc/sonarqube_config.properties\", \"contents\": \"# SonarQube Configuration for Secure SDLC\\n\\n# Project identification\\nsonar.projectKey=company-app\\nsonar.projectName=Company Application\\nsonar.projectVersion=1.0\\n\\n# Source code settings\\nsonar.sources=src/\\nsonar.tests=tests/\\nsonar.sourceEncoding=UTF-8\\nsonar.language=java\\n\\n# Coverage and test results\\nsonar.coverage.jacoco.xmlReportPaths=target/site/jacoco/jacoco.xml\\nsonar.junit.reportPaths=target/surefire-reports\\n\\n# Security-specific settings\\nsonar.security.hotspots.enabled=true\\nsonar.security.review.enabled=true\\n\\n# Quality Gates (fail build on security issues)\\nsonar.qualitygate.wait=true\\nsonar.qualitygate.timeout=300\\n\\n# Security rules configuration\\nsonar.java.checkstyle.reportPaths=target/checkstyle-result.xml\\nsonar.java.pmd.reportPaths=target/pmd.xml\\nsonar.java.spotbugs.reportPaths=target/spotbugsXml.xml\\n\\n# OWASP dependency check integration\\nsonar.dependencyCheck.reportPath=target/dependency-check-report.xml\\nsonar.dependencyCheck.htmlReportPath=target/dependency-check-report.html\\n\\n# Exclusions (avoid scanning test utilities and generated code)\\nsonar.exclusions=**/test/**,**/target/**,**/node_modules/**,**/*.min.js\\nsonar.test.exclusions=**/src/**\\n\\n# Duplication detection\\nsonar.cpd.exclusions=**/generated/**,**/templates/**\\n\\n# Security hotspot thresholds\\nsonar.security.hotspots.threshold.high=0\\nsonar.security.hotspots.threshold.medium=5\\nsonar.security.hotspots.threshold.low=10\\n\\n# Custom security rules\\nsonar.java.libraries=target/dependency/*.jar\\nsonar.java.binaries=target/classes\\nsonar.java.test.libraries=target/dependency/*.jar\\nsonar.java.test.binaries=target/test-classes\"}, {\"name\": \"security_champion_program.md\", \"type\": \"runbook\", \"path\": \"secure-sdlc/security_champion_program.md\", \"contents\": \"# Security Champion Program\\n\\n## Program Overview\\n\\n**Mission**: Embed security expertise within development teams to create a culture of \\\"security by design\\\" while maintaining development velocity and innovation.\\n\\n**Goals**:\\n- Reduce security vulnerabilities in production by 75%\\n- Decrease security finding remediation time from weeks to days\\n- Improve developer security knowledge and skills\\n- Create sustainable security practices within development workflows\\n\\n## Security Champion Role\\n\\n### Responsibilities\\n1. **Security Advocate**: Promote security best practices within development team\\n2. **Knowledge Bridge**: Translate security requirements into actionable development guidance\\n3. **Tool Champion**: Help team adopt and optimize security tools and processes\\n4. **Mentor**: Provide security training and guidance to team members\\n5. **Feedback Loop**: Communicate developer needs and challenges to security team\\n\\n### Time Commitment\\n- **Weekly**: 2-4 hours for security activities and team consultation\\n- **Monthly**: 4 hours security champion meeting and training\\n- **Quarterly**: 8 hours security champion summit and certification\\n\\n### Qualifications\\n- Senior developer with 3+ years experience\\n- Interest in security and willingness to learn\\n- Good communication and mentoring skills\\n- Respected team member who can influence peers\\n\\n## Training Program\\n\\n### Phase 1: Security Foundations (Month 1)\\n- **Week 1**: OWASP Top 10 and secure coding principles\\n- **Week 2**: Threat modeling and security design patterns\\n- **Week 3**: Security testing and code review techniques\\n- **Week 4**: Incident response and vulnerability management\\n\\n### Phase 2: Tool Mastery (Month 2)\\n- **Week 1**: Static application security testing (SAST) tools\\n- **Week 2**: Dynamic testing (DAST) and interactive testing (IAST)\\n- **Week 3**: Software composition analysis (SCA) and dependency management\\n- **Week 4**: Infrastructure security and container scanning\\n\\n### Phase 3: Advanced Topics (Month 3)\\n- **Week 1**: Cloud security and DevSecOps practices\\n- **Week 2**: API security and microservices protection\\n- **Week 3**: Mobile application security\\n- **Week 4**: Security metrics and continuous improvement\\n\\n## Implementation Strategy\\n\\n### Team Integration\\n1. **Sprint Integration**: Include security champion activities in sprint planning\\n2. **Code Review**: Security champion participates in all security-sensitive code reviews\\n3. **Architecture Review**: Champion reviews security implications of design decisions\\n4. **Incident Response**: Champion coordinates team response to security findings\\n\\n### Tool Integration\\n1. **IDE Plugins**: Deploy security plugins for immediate feedback during coding\\n2. **CI/CD Integration**: Configure security scans as part of build pipeline\\n3. **Dashboard Access**: Provide champions with access to security metrics and trends\\n4. **Automation**: Create automated workflows for common security tasks\\n\\n### Communication Channels\\n1. **Slack Channel**: #security-champions for peer support and questions\\n2. **Monthly Meetings**: Share updates, challenges, and best practices\\n3. **Knowledge Base**: Maintain wiki with security guidance and examples\\n4. **Office Hours**: Weekly security team availability for champion questions\\n\\n## Success Metrics\\n\\n### Security Metrics\\n- **Vulnerability Density**: <2 high/critical findings per 1000 lines of code\\n- **Remediation Time**: <48 hours for high/critical findings\\n- **False Positive Rate**: <10% for security scan results\\n- **Security Test Coverage**: >80% of critical application flows\\n\\n### Developer Metrics\\n- **Tool Adoption**: >90% of developers using security IDE plugins\\n- **Training Completion**: 100% team completion of security training modules\\n- **Security Knowledge**: >80% pass rate on quarterly security assessments\\n- **Engagement**: >75% participation in security-related activities\\n\\n### Business Metrics\\n- **Deployment Frequency**: Maintain or improve current deployment velocity\\n- **Lead Time**: No increase in feature delivery time due to security activities\\n- **Production Incidents**: 50% reduction in security-related production issues\\n- **Compliance**: 100% pass rate on security audits and assessments\\n\\n## Recognition and Incentives\\n\\n### Individual Recognition\\n- **Security Champion Certification**: Formal recognition and certificate\\n- **Performance Reviews**: Include security contributions in annual reviews\\n- **Conference Attendance**: Sponsor attendance at security conferences\\n- **Career Development**: Priority consideration for security-related roles\\n\\n### Team Recognition\\n- **Security Excellence Award**: Quarterly award for best security practices\\n- **Team Celebrations**: Recognize major security milestones\\n- **Executive Visibility**: Present team security achievements to leadership\\n- **Innovation Time**: Additional time for security-related innovation projects\\n\\n## Program Evolution\\n\\n### Maturity Levels\\n\\n**Level 1: Reactive** (Months 1-3)\\n- Focus on responding to security findings\\n- Basic tool deployment and training\\n- Establish communication channels\\n\\n**Level 2: Proactive** (Months 4-6)\\n- Shift-left security practices adoption\\n- Threat modeling integration\\n- Automated security testing in CI/CD\\n\\n**Level 3: Predictive** (Months 7-12)\\n- Security metrics and trend analysis\\n- Custom security rule development\\n- Security innovation and research\\n\\n**Level 4: Optimized** (Year 2+)\\n- Security-first development culture\\n- Continuous improvement processes\\n- Industry thought leadership\\n\\n## Common Challenges and Solutions\\n\\n### Challenge: Developer Resistance\\n**Solution**: Start with willing volunteers, demonstrate value through quick wins, provide training and support\\n\\n### Challenge: Time Constraints\\n**Solution**: Integrate security into existing workflows, use automation to reduce manual effort, show ROI of preventing issues\\n\\n### Challenge: Tool Complexity\\n**Solution**: Provide comprehensive training, create simplified workflows, offer ongoing support and mentoring\\n\\n### Challenge: False Positives\\n**Solution**: Tune tools for environment, create exception processes, focus on high-value findings first\\n\\n## Getting Started Checklist\\n\\n- [ ] Identify and recruit initial security champions (1 per 6-8 developers)\\n- [ ] Develop training curriculum tailored to company technology stack\\n- [ ] Set up communication channels and collaboration tools\\n- [ ] Deploy security tools with proper configuration and tuning\\n- [ ] Create security guidelines and best practices documentation\\n- [ ] Establish metrics and reporting dashboard\\n- [ ] Schedule regular champion meetings and training sessions\\n- [ ] Launch pilot program with 1-2 development teams\\n- [ ] Gather feedback and iterate on program design\\n- [ ] Scale successful practices to additional teams\"}], \"mitre\": [\"T1195.002 - Compromise Software Supply Chain\"], \"guidance\": \"NIST SP 800-218 SSDF emphasizes shifting security left in the development process. Key is making security invisible to developers through automation and IDE integration. Security champions bridge the gap between security teams and developers, creating sustainable security culture.\", \"citations\": [\"NIST SP 800-218\", \"OWASP DevSecOps Guideline\"], \"confidence\": 0.89}"}
{"instruction": "How do I set up automated incident response when the SOC team is overwhelmed with alerts?", "input": "", "output": "{\"triage_steps\": [\"Assess current alert volume and false positive rates\", \"Identify high-volume, low-complexity security events for automation\", \"Map current incident response procedures and decision trees\"], \"containment\": [\"Implement basic alert correlation to reduce noise\", \"Deploy automated enrichment for common alert types\", \"Create automated containment for known malware signatures\"], \"remediation\": [\"Deploy SOAR platform with playbook automation\", \"Implement threat intelligence integration for context\", \"Create automated response workflows for common incident types\", \"Establish human oversight and approval gates for critical actions\"], \"how\": {\"prechecks\": [\"Document current incident response procedures and timing\", \"Identify team skills and training needs for SOAR platform\", \"Verify integration capabilities with existing security tools\", \"Test automation logic in sandbox environment before production\"], \"plan\": [\"Phase 1: Deploy SOAR platform and integrate primary security tools\", \"Phase 2: Create basic automation playbooks for high-volume alerts\", \"Phase 3: Implement threat intelligence and enrichment automation\", \"Phase 4: Deploy automated containment for confirmed threats\", \"Phase 5: Add advanced orchestration and custom integrations\"], \"apply\": [\"Deploy Phantom/Splunk SOAR or Microsoft Sentinel automation\", \"Configure API integrations with SIEM, EDR, and network tools\", \"Create automated playbooks using visual workflow designer\", \"Test automation with simulated security events\"], \"validate\": [\"Measure alert processing time reduction (target 80% improvement)\", \"Track false positive rate and analyst satisfaction\", \"Monitor automation success rate and failure scenarios\", \"Verify human oversight controls function properly\"], \"rollback\": [\"Disable automation playbooks while maintaining manual processes\", \"Route all alerts back to human analysts temporarily\", \"Document automation issues and improvements needed\"], \"risk_tradeoffs\": [\"Initial setup time (2-3 weeks) vs 80% reduction in alert processing time\", \"Platform licensing costs vs analyst efficiency gains\", \"Automation complexity vs consistent incident response quality\"]}, \"artifacts\": [{\"name\": \"phantom_playbook.json\", \"type\": \"json\", \"path\": \"soar-automation/phantom_playbook.json\", \"contents\": \"{\\n  \\\"playbook\\\": {\\n    \\\"name\\\": \\\"Malware Detection Response\\\",\\n    \\\"description\\\": \\\"Automated response to confirmed malware detections\\\",\\n    \\\"tags\\\": [\\\"malware\\\", \\\"endpoint\\\", \\\"containment\\\"],\\n    \\\"type\\\": \\\"automation\\\",\\n    \\\"status\\\": \\\"active\\\",\\n    \\\"blocks\\\": [\\n      {\\n        \\\"id\\\": 1,\\n        \\\"type\\\": \\\"start\\\",\\n        \\\"name\\\": \\\"Malware Alert Received\\\",\\n        \\\"parameters\\\": {\\n          \\\"trigger_type\\\": \\\"webhook\\\",\\n          \\\"source\\\": \\\"crowdstrike_edr\\\"\\n        }\\n      },\\n      {\\n        \\\"id\\\": 2,\\n        \\\"type\\\": \\\"action\\\",\\n        \\\"name\\\": \\\"Enrich with Threat Intel\\\",\\n        \\\"app\\\": \\\"virustotal\\\",\\n        \\\"action\\\": \\\"file_reputation\\\",\\n        \\\"parameters\\\": {\\n          \\\"hash\\\": \\\"{{ artifact.file_hash }}\\\",\\n          \\\"timeout\\\": 30\\n        }\\n      },\\n      {\\n        \\\"id\\\": 3,\\n        \\\"type\\\": \\\"decision\\\",\\n        \\\"name\\\": \\\"High Confidence Malware?\\\",\\n        \\\"condition\\\": \\\"{{ virustotal_result.positives > 5 and crowdstrike_confidence > 80 }}\\\",\\n        \\\"true_path\\\": 4,\\n        \\\"false_path\\\": 8\\n      },\\n      {\\n        \\\"id\\\": 4,\\n        \\\"type\\\": \\\"action\\\",\\n        \\\"name\\\": \\\"Isolate Endpoint\\\",\\n        \\\"app\\\": \\\"crowdstrike\\\",\\n        \\\"action\\\": \\\"contain_host\\\",\\n        \\\"parameters\\\": {\\n          \\\"device_id\\\": \\\"{{ artifact.device_id }}\\\",\\n          \\\"reason\\\": \\\"Automated malware containment\\\"\\n        }\\n      },\\n      {\\n        \\\"id\\\": 5,\\n        \\\"type\\\": \\\"action\\\",\\n        \\\"name\\\": \\\"Block Hash Globally\\\",\\n        \\\"app\\\": \\\"palo_alto_firewall\\\",\\n        \\\"action\\\": \\\"block_hash\\\",\\n        \\\"parameters\\\": {\\n          \\\"hash\\\": \\\"{{ artifact.file_hash }}\\\",\\n          \\\"scope\\\": \\\"global\\\"\\n        }\\n      },\\n      {\\n        \\\"id\\\": 6,\\n        \\\"type\\\": \\\"action\\\",\\n        \\\"name\\\": \\\"Create High Priority Ticket\\\",\\n        \\\"app\\\": \\\"servicenow\\\",\\n        \\\"action\\\": \\\"create_ticket\\\",\\n        \\\"parameters\\\": {\\n          \\\"priority\\\": \\\"1-Critical\\\",\\n          \\\"category\\\": \\\"Security Incident\\\",\\n          \\\"description\\\": \\\"Automated malware containment - Host {{ artifact.hostname }} isolated\\\",\\n          \\\"assigned_to\\\": \\\"SOC Team\\\"\\n        }\\n      },\\n      {\\n        \\\"id\\\": 7,\\n        \\\"type\\\": \\\"action\\\",\\n        \\\"name\\\": \\\"Send Executive Notification\\\",\\n        \\\"app\\\": \\\"smtp\\\",\\n        \\\"action\\\": \\\"send_email\\\",\\n        \\\"parameters\\\": {\\n          \\\"to\\\": [\\\"ciso@company.com\\\", \\\"it-director@company.com\\\"],\\n          \\\"subject\\\": \\\"CRITICAL: Malware Detected and Contained\\\",\\n          \\\"body\\\": \\\"Automated systems detected and contained malware on {{ artifact.hostname }}. Incident ticket {{ servicenow_ticket.number }} created. No user action required.\\\"\\n        }\\n      },\\n      {\\n        \\\"id\\\": 8,\\n        \\\"type\\\": \\\"action\\\",\\n        \\\"name\\\": \\\"Create Medium Priority Ticket\\\",\\n        \\\"app\\\": \\\"servicenow\\\",\\n        \\\"action\\\": \\\"create_ticket\\\",\\n        \\\"parameters\\\": {\\n          \\\"priority\\\": \\\"3-Medium\\\",\\n          \\\"category\\\": \\\"Security Alert\\\",\\n          \\\"description\\\": \\\"Potential malware detection requires analyst review - Host {{ artifact.hostname }}\\\",\\n          \\\"assigned_to\\\": \\\"SOC Level 1\\\"\\n        }\\n      },\\n      {\\n        \\\"id\\\": 9,\\n        \\\"type\\\": \\\"end\\\",\\n        \\\"name\\\": \\\"Playbook Complete\\\",\\n        \\\"parameters\\\": {\\n          \\\"status\\\": \\\"success\\\",\\n          \\\"summary\\\": \\\"Malware response playbook completed successfully\\\"\\n        }\\n      }\\n    ]\\n  }\\n}\"}, {\"name\": \"sentinel_automation_rule.json\", \"type\": \"json\", \"path\": \"soar-automation/sentinel_automation_rule.json\", \"contents\": \"{\\n  \\\"$schema\\\": \\\"https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#\\\",\\n  \\\"contentVersion\\\": \\\"1.0.0.0\\\",\\n  \\\"resources\\\": [\\n    {\\n      \\\"type\\\": \\\"Microsoft.SecurityInsights/AutomationRules\\\",\\n      \\\"apiVersion\\\": \\\"2023-04-01-preview\\\",\\n      \\\"name\\\": \\\"BruteForceResponseRule\\\",\\n      \\\"properties\\\": {\\n        \\\"displayName\\\": \\\"Automated Brute Force Response\\\",\\n        \\\"order\\\": 100,\\n        \\\"triggeringLogic\\\": {\\n          \\\"isEnabled\\\": true,\\n          \\\"triggersOn\\\": \\\"Incidents\\\",\\n          \\\"triggersWhen\\\": \\\"Created\\\",\\n          \\\"conditions\\\": [\\n            {\\n              \\\"conditionType\\\": \\\"Property\\\",\\n              \\\"conditionProperties\\\": {\\n                \\\"propertyName\\\": \\\"IncidentTitle\\\",\\n                \\\"operator\\\": \\\"Contains\\\",\\n                \\\"propertyValues\\\": [\\n                  \\\"Brute Force\\\",\\n                  \\\"Multiple Failed Logins\\\",\\n                  \\\"Password Spray\\\"\\n                ]\\n              }\\n            },\\n            {\\n              \\\"conditionType\\\": \\\"Property\\\",\\n              \\\"conditionProperties\\\": {\\n                \\\"propertyName\\\": \\\"IncidentSeverity\\\",\\n                \\\"operator\\\": \\\"Equals\\\",\\n                \\\"propertyValues\\\": [\\\"Medium\\\", \\\"High\\\"]\\n              }\\n            }\\n          ]\\n        },\\n        \\\"actions\\\": [\\n          {\\n            \\\"order\\\": 1,\\n            \\\"actionType\\\": \\\"RunPlaybook\\\",\\n            \\\"actionConfiguration\\\": {\\n              \\\"logicAppResourceId\\\": \\\"/subscriptions/{subscription-id}/resourceGroups/{rg-name}/providers/Microsoft.Logic/workflows/BruteForceResponsePlaybook\\\",\\n              \\\"tenantId\\\": \\\"{tenant-id}\\\"\\n            }\\n          },\\n          {\\n            \\\"order\\\": 2,\\n            \\\"actionType\\\": \\\"ModifyProperties\\\",\\n            \\\"actionConfiguration\\\": {\\n              \\\"status\\\": \\\"Active\\\",\\n              \\\"owner\\\": {\\n                \\\"objectId\\\": \\\"{soc-team-object-id}\\\",\\n                \\\"email\\\": \\\"soc@company.com\\\",\\n                \\\"assignedTo\\\": \\\"SOC Team\\\",\\n                \\\"userPrincipalName\\\": \\\"soc@company.com\\\"\\n              },\\n              \\\"tags\\\": [\\n                {\\n                  \\\"tag\\\": \\\"AutomatedResponse\\\"\\n                },\\n                {\\n                  \\\"tag\\\": \\\"BruteForce\\\"\\n                }\\n              ]\\n            }\\n          }\\n        ]\\n      }\\n    }\\n  ]\\n}\"}, {\"name\": \"alert_correlation.py\", \"type\": \"python\", \"path\": \"soar-automation/alert_correlation.py\", \"contents\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\nAlert Correlation and De-duplication Engine\\nReduces alert noise by correlating related security events\\n\\\"\\\"\\\"\\n\\nimport json\\nimport time\\nfrom datetime import datetime, timedelta\\nfrom collections import defaultdict\\nfrom typing import Dict, List, Any\\n\\nclass AlertCorrelator:\\n    def __init__(self, time_window_minutes=15, similarity_threshold=0.8):\\n        self.time_window = timedelta(minutes=time_window_minutes)\\n        self.similarity_threshold = similarity_threshold\\n        self.alert_cache = defaultdict(list)\\n        \\n    def correlate_alerts(self, new_alert: Dict[str, Any]) -> Dict[str, Any]:\\n        \\\"\\\"\\\"\\n        Correlate new alert with existing alerts to reduce duplicates\\n        \\\"\\\"\\\"\\n        correlation_key = self._generate_correlation_key(new_alert)\\n        current_time = datetime.now()\\n        \\n        # Clean old alerts from cache\\n        self._cleanup_cache(current_time)\\n        \\n        # Check for existing correlations\\n        existing_alerts = self.alert_cache[correlation_key]\\n        similar_alerts = self._find_similar_alerts(new_alert, existing_alerts)\\n        \\n        if similar_alerts:\\n            # Update existing correlation\\n            master_alert = similar_alerts[0]\\n            master_alert['correlation_count'] += 1\\n            master_alert['last_seen'] = current_time\\n            master_alert['severity'] = self._calculate_escalated_severity(\\n                master_alert['severity'], \\n                master_alert['correlation_count']\\n            )\\n            return {\\n                'action': 'update_existing',\\n                'alert_id': master_alert['id'],\\n                'correlation_count': master_alert['correlation_count'],\\n                'escalated': master_alert['correlation_count'] > 5\\n            }\\n        else:\\n            # Create new alert with correlation tracking\\n            new_alert['correlation_count'] = 1\\n            new_alert['first_seen'] = current_time\\n            new_alert['last_seen'] = current_time\\n            self.alert_cache[correlation_key].append(new_alert)\\n            return {\\n                'action': 'create_new',\\n                'alert_id': new_alert['id'],\\n                'correlation_key': correlation_key\\n            }\\n    \\n    def _generate_correlation_key(self, alert: Dict[str, Any]) -> str:\\n        \\\"\\\"\\\"Generate correlation key based on alert attributes\\\"\\\"\\\"\\n        key_elements = [\\n            alert.get('source_ip', ''),\\n            alert.get('destination_ip', ''),\\n            alert.get('user', ''),\\n            alert.get('alert_type', ''),\\n            alert.get('rule_name', '')\\n        ]\\n        return '|'.join(str(elem).lower() for elem in key_elements)\\n    \\n    def _find_similar_alerts(self, new_alert: Dict[str, Any], existing_alerts: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\\n        \\\"\\\"\\\"Find similar alerts within time window\\\"\\\"\\\"\\n        current_time = datetime.now()\\n        similar = []\\n        \\n        for alert in existing_alerts:\\n            if current_time - alert['last_seen'] <= self.time_window:\\n                similarity_score = self._calculate_similarity(new_alert, alert)\\n                if similarity_score >= self.similarity_threshold:\\n                    similar.append(alert)\\n        \\n        return similar\\n    \\n    def _calculate_similarity(self, alert1: Dict[str, Any], alert2: Dict[str, Any]) -> float:\\n        \\\"\\\"\\\"Calculate similarity score between two alerts\\\"\\\"\\\"\\n        similarity_factors = [\\n            ('source_ip', 0.3),\\n            ('destination_ip', 0.2),\\n            ('user', 0.2),\\n            ('alert_type', 0.2),\\n            ('rule_name', 0.1)\\n        ]\\n        \\n        total_similarity = 0.0\\n        for field, weight in similarity_factors:\\n            val1 = str(alert1.get(field, '')).lower()\\n            val2 = str(alert2.get(field, '')).lower()\\n            if val1 and val2 and val1 == val2:\\n                total_similarity += weight\\n        \\n        return total_similarity\\n    \\n    def _calculate_escalated_severity(self, original_severity: str, correlation_count: int) -> str:\\n        \\\"\\\"\\\"Escalate severity based on correlation count\\\"\\\"\\\"\\n        severity_levels = ['low', 'medium', 'high', 'critical']\\n        current_index = severity_levels.index(original_severity.lower())\\n        \\n        if correlation_count > 10:\\n            escalation = 2\\n        elif correlation_count > 5:\\n            escalation = 1\\n        else:\\n            escalation = 0\\n        \\n        new_index = min(current_index + escalation, len(severity_levels) - 1)\\n        return severity_levels[new_index]\\n    \\n    def _cleanup_cache(self, current_time: datetime):\\n        \\\"\\\"\\\"Remove old alerts from cache\\\"\\\"\\\"\\n        cutoff_time = current_time - (self.time_window * 2)\\n        \\n        for key in list(self.alert_cache.keys()):\\n            self.alert_cache[key] = [\\n                alert for alert in self.alert_cache[key]\\n                if alert['last_seen'] > cutoff_time\\n            ]\\n            if not self.alert_cache[key]:\\n                del self.alert_cache[key]\\n\\n# Example usage\\nif __name__ == '__main__':\\n    correlator = AlertCorrelator()\\n    \\n    # Sample alert\\n    alert = {\\n        'id': 'alert_123',\\n        'source_ip': '192.168.1.100',\\n        'destination_ip': '10.0.0.50',\\n        'user': 'john.doe',\\n        'alert_type': 'failed_login',\\n        'rule_name': 'Multiple Failed Login Attempts',\\n        'severity': 'medium',\\n        'timestamp': datetime.now()\\n    }\\n    \\n    result = correlator.correlate_alerts(alert)\\n    print(json.dumps(result, indent=2, default=str))\"}, {\"name\": \"soar_playbook_library.md\", \"type\": \"runbook\", \"path\": \"soar-automation/soar_playbook_library.md\", \"contents\": \"# SOAR Playbook Library\\n\\n## High-Volume Alert Playbooks\\n\\n### 1. Failed Login Correlation\\n**Trigger**: Multiple failed login alerts from same source IP\\n**Automation Steps**:\\n1. Correlate failed login events within 15-minute window\\n2. Check source IP reputation (VirusTotal, AbuseIPDB)\\n3. If >10 attempts: Automatically block IP at firewall\\n4. If >20 attempts: Create high-priority incident\\n5. Notify user via email if their account is targeted\\n\\n**Human Oversight**: Manual review required for internal IPs\\n\\n### 2. Malware Detection Response\\n**Trigger**: Endpoint protection detects malware\\n**Automation Steps**:\\n1. Enrich file hash with threat intelligence\\n2. If confidence >80%: Isolate endpoint automatically\\n3. Block file hash across all security tools\\n4. Create forensic collection task\\n5. Notify user and their manager\\n6. Create incident ticket with timeline\\n\\n**Human Oversight**: Analyst approval required before isolation\\n\\n### 3. Phishing Email Response\\n**Trigger**: Email security reports suspicious email\\n**Automation Steps**:\\n1. Extract URLs and attachments for analysis\\n2. Check URLs against threat intelligence feeds\\n3. If malicious: Remove email from all mailboxes\\n4. Block URLs at web proxy\\n5. Identify users who clicked links\\n6. Force password reset for affected users\\n7. Send security awareness reminder\\n\\n**Human Oversight**: Manual review before user password resets\\n\\n### 4. Vulnerability Scanner Alerts\\n**Trigger**: Critical vulnerability detected\\n**Automation Steps**:\\n1. Cross-reference with asset inventory\\n2. Check if system is internet-facing\\n3. Verify if patches are available\\n4. Create patching ticket with priority based on exposure\\n5. If public exploit exists: Create emergency change ticket\\n6. Notify system owner and security team\\n\\n**Human Oversight**: Emergency patching requires manager approval\\n\\n### 5. Data Loss Prevention (DLP) Violations\\n**Trigger**: Sensitive data detected in unauthorized location\\n**Automation Steps**:\\n1. Classify data sensitivity level\\n2. Identify data owner and user responsible\\n3. Quarantine file if possible\\n4. Create compliance tracking ticket\\n5. Notify data owner and user's manager\\n6. If PII/PHI: Create regulatory reporting task\\n\\n**Human Oversight**: Legal team review for regulatory implications\\n\\n## Advanced Orchestration Playbooks\\n\\n### 6. Advanced Persistent Threat (APT) Detection\\n**Trigger**: Multiple indicators suggest coordinated attack\\n**Automation Steps**:\\n1. Correlate alerts across multiple security tools\\n2. Create attack timeline and killchain analysis\\n3. Identify all potentially compromised systems\\n4. Isolate affected systems from network\\n5. Collect forensic evidence automatically\\n6. Create war room and notify incident response team\\n7. Engage external forensics firm if needed\\n\\n**Human Oversight**: CISO approval required for external engagement\\n\\n### 7. Insider Threat Detection\\n**Trigger**: Unusual user behavior patterns detected\\n**Automation Steps**:\\n1. Analyze user's recent access patterns\\n2. Check for off-hours access or unusual locations\\n3. Review file access and download patterns\\n4. Correlate with HR data (termination, disciplinary action)\\n5. Create discrete investigation case\\n6. Notify HR and legal teams confidentially\\n7. Enable enhanced monitoring without alerting user\\n\\n**Human Oversight**: HR and legal review before any action\\n\\n### 8. Supply Chain Compromise\\n**Trigger**: Indicators of compromised software or vendor\\n**Automation Steps**:\\n1. Inventory all systems using affected software\\n2. Check for indicators of compromise\\n3. Isolate affected systems if threats detected\\n4. Create vendor communication task\\n5. Notify all customers if we're affected vendor\\n6. Create supply chain risk assessment task\\n\\n**Human Oversight**: Executive approval for customer notifications\\n\\n## Implementation Guidelines\\n\\n### Playbook Design Principles\\n1. **Start Simple**: Begin with high-volume, low-complexity alerts\\n2. **Human in the Loop**: Always include human oversight for critical decisions\\n3. **Rollback Capability**: Ensure all automated actions can be reversed\\n4. **Extensive Logging**: Log all automated actions for audit trail\\n5. **Continuous Improvement**: Regular playbook updates based on lessons learned\\n\\n### Testing Requirements\\n1. **Sandbox Testing**: All playbooks tested in isolated environment\\n2. **Purple Team Exercises**: Test playbooks with simulated attacks\\n3. **False Positive Handling**: Ensure graceful handling of incorrect data\\n4. **Performance Testing**: Validate playbooks don't overwhelm target systems\\n5. **Disaster Recovery**: Test playbook functionality during outages\\n\\n### Metrics and KPIs\\n1. **Alert Processing Time**: Target 80% reduction in manual processing\\n2. **False Positive Rate**: <10% for automated actions\\n3. **Playbook Success Rate**: >95% successful completion\\n4. **Mean Time to Containment**: <30 minutes for confirmed threats\\n5. **Analyst Satisfaction**: >4/5 rating for automation helpfulness\\n\\n### Governance and Approval\\n1. **Playbook Review**: Monthly review of all active playbooks\\n2. **Change Management**: All playbook changes follow change control process\\n3. **Risk Assessment**: Annual risk assessment of automation capabilities\\n4. **Compliance**: Ensure playbooks meet regulatory requirements\\n5. **Documentation**: Maintain current documentation for all playbooks\\n\\n## Getting Started Checklist\\n\\n### Phase 1: Foundation (Week 1-2)\\n- [ ] Install and configure SOAR platform\\n- [ ] Integrate with primary security tools (SIEM, EDR, Firewall)\\n- [ ] Create service accounts and API credentials\\n- [ ] Set up secure communication channels\\n- [ ] Train team on SOAR platform basics\\n\\n### Phase 2: Basic Playbooks (Week 3-4)\\n- [ ] Deploy failed login correlation playbook\\n- [ ] Implement basic malware response automation\\n- [ ] Create simple ticket creation workflows\\n- [ ] Set up email notification templates\\n- [ ] Test all playbooks in sandbox environment\\n\\n### Phase 3: Advanced Features (Week 5-8)\\n- [ ] Add threat intelligence integrations\\n- [ ] Implement complex decision trees\\n- [ ] Create custom enrichment workflows\\n- [ ] Deploy advanced correlation rules\\n- [ ] Add metrics and reporting dashboards\\n\\n### Phase 4: Optimization (Week 9-12)\\n- [ ] Tune playbooks based on operational experience\\n- [ ] Add additional tool integrations\\n- [ ] Implement advanced use cases\\n- [ ] Create custom apps and connectors\\n- [ ] Establish continuous improvement process\"}], \"mitre\": [\"T1078 - Valid Accounts\", \"T1110 - Brute Force\"], \"guidance\": \"Focus on high-volume, low-complexity alerts first like failed logins and malware detections. Use correlation to reduce noise before creating incidents. Always include human oversight for critical containment actions. Start with 80% automation goal - perfect automation isn't necessary.\", \"citations\": [\"NIST SP 800-61r2\", \"SANS SOAR Implementation Guide\"], \"confidence\": 0.87}"}