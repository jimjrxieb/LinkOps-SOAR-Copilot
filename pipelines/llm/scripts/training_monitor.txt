======================================================================
ğŸ¯ WHIS LLM TRAINING MONITOR - LIVE PIPELINE
======================================================================
ğŸ“… Updated: 2025-08-22 21:23:48
â±ï¸ Running Time: 14840s | Iteration: 2607

ğŸ“Š TRAINING PROCESS:
------------------------------
âŒ Status: NOT RUNNING

ğŸ® GPU STATUS:
------------------------------
âš¡ Utilization: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%
ğŸ’¾ VRAM: 7350MB / 16303MB
ğŸŒ¡ï¸ Temperature: 45Â°C
ğŸ“¦ Phase: MODEL LOADED

ğŸ”§ LLM FINE-TUNING PIPELINE:
------------------------------
â³ 1. Load Dataset
âœ… 2. Load Base Model
âœ… 3. Apply LoRA Adapters
â³ 4. Training Loop
â³ 5. Save Checkpoint
â³ 6. Complete

ğŸ’¾ MODEL OUTPUT:
------------------------------
â³ No model output yet...

âš™ï¸ CONFIGURATION:
------------------------------
ğŸ“š Base Model: CodeLlama-7b-Instruct
ğŸ”§ Method: LoRA (Low-Rank Adaptation)
ğŸ“Š Dataset: 23 cybersecurity examples
ğŸ¯ Optimization: 4-bit quantization

======================================================================